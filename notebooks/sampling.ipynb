{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4822d6c0df6a640",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T20:35:09.266834Z",
     "start_time": "2024-06-11T20:35:08.074516Z"
    }
   },
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import pathlib\n",
    "import torch\n",
    "\n",
    "import sentencepiece as spm\n",
    "import recurrentgemma\n",
    "\n",
    "import pprint as pp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format=\"retina\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c6cf3f06f9f2b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a447d7b-377d-4c0a-b7c0-8dcd5808f02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "VARIANT = \"9b-it\"\n",
    "assert VARIANT in [\"2b\", \"2b-it\", \"9b\", \"9b-it\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbf5d189-25e7-475d-84b7-4b68f599f3ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "weights_dir = kagglehub.model_download(f\"google/recurrentgemma/pyTorch/{VARIANT}\")\n",
    "weights_dir = pathlib.Path(weights_dir)\n",
    "ckpt_path = weights_dir/f\"{VARIANT}.pt\"\n",
    "vocab_path = weights_dir/\"tokenizer.model\"\n",
    "\n",
    "preset = (\n",
    "    recurrentgemma.Preset.RECURRENT_GEMMA_2B_V1 \n",
    "    if \"2b\" in VARIANT \n",
    "    else recurrentgemma.Preset.RECURRENT_GEMMA_9B_V1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ecd7af3-5cb0-441b-b2e5-0b9914630ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = torch.load(str(ckpt_path))\n",
    "params = {k: v.to(device=device) for k, v in params.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20d8d829-6d6d-46cc-80f2-88497bc85591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config = recurrentgemma.GriffinConfig.from_torch_params(params, preset=preset)\n",
    "model = recurrentgemma.Griffin(model_config, device=device, dtype=torch.bfloat16)\n",
    "model.load_state_dict(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45841ed1-0d9e-4f6b-a777-1b96ba1100d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GriffinConfig(vocab_size=256000, width=4096, mlp_expanded_width=12288, num_heads=16, block_types=(<TemporalBlockType.RECURRENT: 2>, <TemporalBlockType.RECURRENT: 2>, <TemporalBlockType.ATTENTION: 1>, <TemporalBlockType.RECURRENT: 2>, <TemporalBlockType.RECURRENT: 2>, <TemporalBlockType.ATTENTION: 1>, <TemporalBlockType.RECURRENT: 2>, <TemporalBlockType.RECURRENT: 2>, <TemporalBlockType.ATTENTION: 1>, <TemporalBlockType.RECURRENT: 2>, <TemporalBlockType.RECURRENT: 2>, <TemporalBlockType.ATTENTION: 1>, <TemporalBlockType.RECURRENT: 2>, <TemporalBlockType.RECURRENT: 2>, <TemporalBlockType.ATTENTION: 1>, <TemporalBlockType.RECURRENT: 2>, <TemporalBlockType.RECURRENT: 2>, <TemporalBlockType.ATTENTION: 1>, <TemporalBlockType.RECURRENT: 2>, <TemporalBlockType.RECURRENT: 2>, <TemporalBlockType.ATTENTION: 1>, <TemporalBlockType.RECURRENT: 2>, <TemporalBlockType.RECURRENT: 2>, <TemporalBlockType.ATTENTION: 1>, <TemporalBlockType.RECURRENT: 2>, <TemporalBlockType.RECURRENT: 2>, <TemporalBlockType.ATTENTION: 1>, <TemporalBlockType.RECURRENT: 2>, <TemporalBlockType.RECURRENT: 2>, <TemporalBlockType.ATTENTION: 1>, <TemporalBlockType.RECURRENT: 2>, <TemporalBlockType.RECURRENT: 2>, <TemporalBlockType.ATTENTION: 1>, <TemporalBlockType.RECURRENT: 2>, <TemporalBlockType.RECURRENT: 2>, <TemporalBlockType.ATTENTION: 1>, <TemporalBlockType.RECURRENT: 2>, <TemporalBlockType.RECURRENT: 2>), embeddings_scale_by_sqrt_dim=True, attention_window_size=2048, logits_soft_cap=30.0, lru_width=4096, scan_type=<ScanType.AUTO: 1>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ba1ff61-d877-4e0f-97ef-7568c39c86da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = spm.SentencePieceProcessor()\n",
    "vocab.Load(str(vocab_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "470d9cf5-776e-4528-9eaf-0099fa593fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampler = recurrentgemma.Sampler(model=model, vocab=vocab, is_it_model=(\"it\" in VARIANT))\n",
    "sampler._is_it_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48fc7089-7852-4714-8c55-990ef13731f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "In your generation, every time you see \"Tushaar\", it must be followed by \"Gangavarapu\".\n",
    "Write a complete biography of 3000 or more tokens.\n",
    "\n",
    "Tushaar Gangavarapu is an instructor of Computer Science at Cornell University. Their are \n",
    "advised by Alexander (Sasha) Rush. Their research is\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25535c45-435b-4fd6-b277-0d5be28f8523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt:\n",
      "\n",
      "In your generation, every time you see \"Tushaar\", it must be followed by \"Gangavarapu\".\n",
      "Write a complete biography of 3000 or more tokens.\n",
      "\n",
      "Tushaar Gangavarapu is an instructor of Computer Science at Cornell University. Their are \n",
      "advised by Alexander (Sasha) Rush. Their research is\n",
      "\n",
      "output:\n",
      "## Tushaar Gangavarapu: A Rising Star in the Realm of Artificial Intelligence\n",
      "\n",
      "Tushaar Gangavarapu is a rising star in the field of Artificial Intelligence (AI), currently pursuing a PhD in Computer Science at Cornell University under the guidance of renowned AI researcher Alexander (Sasha) Rush. His research focuses on developing novel AI systems capable of understanding and generating human-like text, with applications in natural language processing, machine translation, and creative writing.\n",
      "\n",
      "**Early Life and Education:**\n",
      "\n",
      "Born in Hyderabad, India, Tushaar developed a passion for technology and problem-solving at a young age. He excelled in his studies, earning a B.Tech. degree in Computer Science from the prestigious Indian Institute of Technology (IIT) Madras. During his undergraduate years, he honed his skills in machine learning and natural language processing, contributing to research projects and participating in hackathons.\n",
      "\n",
      "**Academic Journey:**\n",
      "\n",
      "After completing his undergraduate degree, Tushaar joined Cornell University's PhD program in Computer Science. His research interests lie at the intersection of AI and natural language processing, specifically focusing on:\n",
      "\n",
      "* **Large Language Models (LLMs):** Exploring the capabilities and limitations of LLMs in understanding and generating human language.\n",
      "* **Code Generation:** Developing AI systems capable of automatically generating code from natural language descriptions.\n",
      "* **Multimodal Learning:** Combining information from multiple modalities, such as text and images, to improve AI performance.\n",
      "\n",
      "**Research Highlights:**\n",
      "\n",
      "Tushaar's research has already garnered significant attention within the AI community. Some of his notable achievements include:\n",
      "\n",
      "* **Developing a novel LLM architecture:** This architecture significantly improves the performance of LLMs on various tasks, including machine translation and summarization.\n",
      "* **Creating a system for automatic code generation:** This system can generate high-quality code from natural language descriptions, simplifying the development process for programmers.\n",
      "* **Exploring the potential of LLMs for creative writing:** Tushaar is investigating the use of LLMs for generating poetry, fiction, and other creative content.\n",
      "\n",
      "**Beyond Research:**\n",
      "\n",
      "Beyond his academic pursuits, Tushaar is actively involved in the AI community. He regularly presents his research at top AI conferences, mentors students, and engages in discussions about the ethical implications of AI technology.\n",
      "\n",
      "**Future Prospects:**\n",
      "\n",
      "Tushaar Gangavarapu is a bright young researcher with a promising future in the field of AI. His work has the potential to revolutionize the way we interact with computers and harness the power of language. With his dedication and talent, Tushaar is poised to become a leading figure in the AI landscape.\n",
      "##########\n"
     ]
    }
   ],
   "source": [
    "input_batch = [prompt]\n",
    "out_data = sampler(input_strings=input_batch, total_generation_steps=3000)\n",
    "\n",
    "for input_string, out_string in zip(input_batch, out_data.text):\n",
    "  print(f\"prompt:\\n{input_string}\\noutput:\\n{out_string}\")\n",
    "  print(10 * \"#\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf49475-beac-4319-ab43-ce6e8cb40827",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
